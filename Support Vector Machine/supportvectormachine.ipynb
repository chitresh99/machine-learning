{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OSFHVHmzWs0I"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_dataset(dataframes, oversample=False):\n",
        "    x = dataframes[dataframes.columns[:-1]].values\n",
        "    y = dataframes[dataframes.columns[-1]].values\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(x)\n",
        "\n",
        "    data = np.hstack((X, np.reshape(y, (-1, 1))))  # stacking all the arrays together like take the first array and take the second array and stack them together\n",
        "\n",
        "    if oversample:\n",
        "        ros = RandomOverSampler()\n",
        "        X, y = ros.fit_resample(X, y)  # this will take whatever is present in less quantity and make more of it i mean it will increase the data\n",
        "\n",
        "    return data, X, y\n",
        "    # x is two dimensional\n",
        "    # y is one dimensional\n",
        "    # we made our y a 2d array"
      ],
      "metadata": {
        "id": "E_Z1ttKPXNeL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('magic04.data')"
      ],
      "metadata": {
        "id": "MWxjIIm8XPi0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, X, y = scale_dataset(df, oversample=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "FOvk-Jd3Xwjb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC()\n",
        "svm_model = svm_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "5Gj9j3P4X3iQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm_model.predict(X_test)"
      ],
      "metadata": {
        "id": "Aa2e-JfzYDYE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1OmjW3KYI1S",
        "outputId": "a0f351d3-0c4d-4d1c-8726-b7174a4baeba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.82      0.90      0.86      2498\n",
            "           h       0.88      0.80      0.84      2435\n",
            "\n",
            "    accuracy                           0.85      4933\n",
            "   macro avg       0.85      0.85      0.85      4933\n",
            "weighted avg       0.85      0.85      0.85      4933\n",
            "\n"
          ]
        }
      ]
    }
  ]
}