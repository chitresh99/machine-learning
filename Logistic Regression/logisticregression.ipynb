{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wuoMwC7oCmvc"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_dataset(dataframes, oversample=False):\n",
        "    x = dataframes[dataframes.columns[:-1]].values\n",
        "    y = dataframes[dataframes.columns[-1]].values\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(x)\n",
        "\n",
        "    data = np.hstack((X, np.reshape(y, (-1, 1))))  # stacking all the arrays together like take the first array and take the second array and stack them together\n",
        "\n",
        "    if oversample:\n",
        "        ros = RandomOverSampler()\n",
        "        X, y = ros.fit_resample(X, y)  # this will take whatever is present in less quantity and make more of it i mean it will increase the data\n",
        "\n",
        "    return data, X, y\n",
        "    # x is two dimensional\n",
        "    # y is one dimensional\n",
        "    # we made our y a 2d array"
      ],
      "metadata": {
        "id": "s1FLSEXHC2SZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('magic04.data')"
      ],
      "metadata": {
        "id": "iALg6IKvC5nc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, X, y = scale_dataset(df, oversample=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "tz-cHBicC9Li"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you split a dataset into training and testing sets, there's usually some randomness involved in the process to ensure that the data is divided randomly. However, if you want to ensure reproducibility, meaning that the same random splitting is obtained every time you run your code, you can set the random_state parameter to a fixed value."
      ],
      "metadata": {
        "id": "4XcIxvCFVYZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, if you set random_state=42, the data will be split in the same way every time you run the code with random_state=42. If you use a different value, like random_state=10, the data will be split differently."
      ],
      "metadata": {
        "id": "6pKXaxhmVaTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use this so we get the same output everytime when we run the code but the data is divided randomly"
      ],
      "metadata": {
        "id": "B6af50aiVmRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lg_model = LogisticRegression()\n",
        "lg_model = lg_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "eGWGkhV0C_fb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = lg_model.predict(X_test)"
      ],
      "metadata": {
        "id": "GW2VFfPiDBuP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdveshL8DDWl",
        "outputId": "a20c55b2-0099-4547-eb87-bf8effae6f71"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           g       0.75      0.83      0.79      2498\n",
            "           h       0.80      0.72      0.76      2435\n",
            "\n",
            "    accuracy                           0.77      4933\n",
            "   macro avg       0.77      0.77      0.77      4933\n",
            "weighted avg       0.77      0.77      0.77      4933\n",
            "\n"
          ]
        }
      ]
    }
  ]
}